{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Gy17hKcuxnv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Step 1: Install nataili\n",
        "#@markdown Click the play button, confirm output contains no bad looking errors.\n",
        "\n",
        "#@markdown Warnings to the effect of `WARNING: The following packages were previously imported in this runtime:` can be ignored.\n",
        "\n",
        "#@markdown This will take around 5 minutes, depending on initial conditions of colab.\n",
        "\n",
        "%cd /content/\n",
        "!git clone https://github.com/tazlin/nataili.git --branch sss --single-branch\n",
        "%cd /content/nataili/\n",
        "!pip install xformers\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Step 2: Setup nataili\n",
        "\n",
        "%cd /content/nataili\n",
        "from PIL import Image\n",
        "from nataili.model_manager.super import ModelManager\n",
        "from nataili.stable_diffusion.compvis import CompVis\n",
        "\n",
        "\n",
        "mm = ModelManager(compvis=True, esrgan=True, gfpgan=True, codeformer=True)\n",
        "\n",
        "if mm is not None and mm.load(\"GFPGAN\"):\n",
        "  print()\n",
        "  print(\"-> Everything went OK. You can proceed.\")\n"
      ],
      "metadata": {
        "id": "WM8BcY1OvA_f",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Step 3: Load model\n",
        "#@markdown You can enter the \"name\" field of any `.ckpt` model from https://github.com/Haidra-Org/AI-Horde-image-model-reference/blob/main/stable_diffusion.json.\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown You can rerun this cell to load a different model.\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown Note that `.safetensors` models will not work.\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "\n",
        "model_to_load = \"Zeipher Female Model\" #@param {type:\"string\"}\n",
        "\n",
        "_loaded_models = list(mm.compvis.loaded_models.keys())\n",
        "for models_loaded in _loaded_models:\n",
        "  mm.unload_model(models_loaded)\n",
        "\n",
        "if mm.load(model_to_load):\n",
        "  print()\n",
        "  print(f\"-> Model '{model_to_load}' loaded successfully.\")\n",
        "else:\n",
        "  print(\"-> Something went wrong. Try rerunning this cell, or if that does not work,\")\n",
        "  print(\"-> go to the file bar, select 'Runtime' and 'Disconnect and Delete Runtime'\")\n",
        "  print(\"-> and restart from the beginnning.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "flKv59ROxYA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Generate Images\n",
        "#@markdown On the left bar of this window, is a folder icon. All images will be output to the folder `samples`.\n",
        "from nataili.gfpgan import gfpgan\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "\n",
        "compvis = CompVis(\n",
        "    model=mm.loaded_models[model_to_load],\n",
        "    model_name=model_to_load,\n",
        "    output_dir='/content/',\n",
        "    disable_voodoo=True,\n",
        ")\n",
        "\n",
        "seed = 0 #@param {type:\"integer\"}\n",
        "#@markdown *Set seed to 0 to have it be random. The seed used will be output below and will be in the filename*\n",
        "if seed and seed < 0:\n",
        "  seed = None\n",
        "if not seed:\n",
        "  seed = None\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "combined_prompt = prompt if not negative_prompt else f\"{prompt}###{negative_prompt}\"\n",
        "width = 512 #@param {type:\"integer\"}\n",
        "height = 768 #@param {type:\"integer\"}\n",
        "\n",
        "steps = 50 #@param {type:\"integer\"}\n",
        "sampler_name = \"k_lms\" #@param [\"k_lms\", \"DDIM\", \"k_dpm_2_a\", \"k_dpm_2\", \"k_euler_a\", \"k_euler\", \"k_heun\", \"k_lms\", \"k_dpm_fast\", \"k_dpm_adaptive\", \"k_dpmpp_2s_a\", \"k_dpmpp_2m\", \"k_dpmpp_sde\"]\n",
        "cfg_scale = 8 #@param {type:\"number\"}\n",
        "clip_skip = 6 #@param {type:\"integer\"}\n",
        "karras = True #@param {type:\"boolean\"}\n",
        "if karras:\n",
        "  sampler_name = sampler_name + \"_karras\"\n",
        "\n",
        "use_gfpgan = True #@param {type:\"boolean\"}\n",
        "ddim_eta = 1 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "batches = 2 #@param {type:\"integer\"}\n",
        "#@markdown *Batches sets how many generations to do. Each generation made this way will have the seed incremented by 1.*\n",
        "\n",
        "if width % 64 != 0 or height % 64 != 0:\n",
        "  print(\"Both width and height must be divisible by 64\")\n",
        "elif seed and seed > (2**32 - 1):\n",
        "  print(f\"Seed needs to be less than {2**32 - 1}\")\n",
        "else:\n",
        "  gfpgan_model = gfpgan(mm.loaded_models[\"GFPGAN\"], output_dir='/content/samples/gfpgan')\n",
        "  for i in range(batches):\n",
        "    if not seed or seed < 0:\n",
        "      seed = random.randint(0, 2**32 - 1)\n",
        "    compvis.generate(\n",
        "        seed=seed,\n",
        "        prompt=combined_prompt,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        ddim_steps=steps,\n",
        "        sampler_name=sampler_name,\n",
        "        cfg_scale=cfg_scale,\n",
        "        clip_skip=clip_skip,\n",
        "        ddim_eta=ddim_eta,\n",
        "      )\n",
        "    plt.figure()\n",
        "    print(f\"seed {i+1}: {seed}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(compvis.output_images[i])\n",
        "    plt.show()\n",
        "    if use_gfpgan:\n",
        "      gfpgan_model(input_image=compvis.output_images[-1], strength=1)\n",
        "      print(\"with gfpgan:\")\n",
        "      plt.figure()\n",
        "      plt.axis(\"off\")\n",
        "      plt.imshow(gfpgan_model.output_images[i])\n",
        "      plt.show()\n",
        "\n",
        "    if seed:\n",
        "      seed += 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qmX_ThIN3HYz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}